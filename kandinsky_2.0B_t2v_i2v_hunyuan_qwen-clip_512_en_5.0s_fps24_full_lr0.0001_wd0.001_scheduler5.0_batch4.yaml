camera_movement: zoomin
common:
  experiment_name: zoomin_lr1e-4_2gpu
  experiment_dir: /home/jovyan/shares/SR008.fs2/vladimir/kandinsky5/kandinsky5_0/kandinsky5_video_19B/kandinsky5_video_19B_T2V_I2V_512_768
  log_dir: /home/jovyan/shares/SR008.fs2/dmitrienko/kandinsky-5-0/saved_models/2B_r512_flash/
  checkpoint_dir: /home/jovyan/shares/SR008.fs2/dmitrienko/kandinsky-5-0/saved_models/2B_r512_flash/
  visual_size: 512
  train_steps: 10000
  fps: 24
  scale_factor:
  - 1.0
  - 2.0
  - 2.0
  conf_path: /home/jovyan/shares/SR008.fs2/dmitrienko/kandinsky-5-0/saved_models/2B_r512_flash//zoomin_lr1e-4_2gpu/kandinsky_2.0B_t2v_i2v_hunyuan_qwen-clip_512_en_5.0s_fps24_full_lr0.0001_wd0.001_scheduler5.0_batch4.yaml
configs:
- new/lora/trainer_2gpu.yaml
- new/lora/data_512.yaml
- new/lora/metrics.yaml
- new/lora/hunyuan.yaml
- new/lora/clip_qwen7b.yaml
- new/lora/dit_2B_flash.yaml
trainer:
  params:
    visual_cond_prob: 0.2
    scale_factor: ${common.scale_factor}
    ema_decay: 0.999
    scheduler_scale: 5.0
    devices: 2
    num_nodes: 1
  device_meshs:
    dit:
      fsdp_mesh: 2
      tp_mesh: 1
    text_embedder:
      fsdp_mesh: 2
  checkpoint_path: /home/jovyan/shares/SR008.fs2/dmitrienko/kandinsky-5-0/saved_models/2B_r512_flash//zoomin_lr1e-4_2gpu/last
checkpoint:
  root_dir: ${common.checkpoint_dir}/${common.experiment_name}
  last_save_interval: 500
  regular_save_interval: 1000
logger:
  log_interval: 10
  tensorboard:
    root_dir: ${common.log_dir}
    default_hp_metric: false
    name: ${common.experiment_name}
optimizer:
  max_norm: 1.0
  params:
    lr: 0.0001
    weight_decay: 0.001
    betas:
    - 0.9
    - 0.95
    eps: 1.0e-08
scheduler:
  params:
    num_warmup_steps: 500
data:
  s3_credentials: null
  visual_size: ${common.visual_size}
  uncond_prob: 0.1
  max_seq_len: 62
  max_video_len: 31
  cut_video: true
  data_params:
    video:
      sampling_prob: 1.0
      data_file: /home/jovyan/dmitrienko/workspace/genai-team/kandinsky-5/data_encoding/lora_csv/zoom_in_speedup/
      filters: []
      latent_dir: /home/jovyan/dmitrienko/datasets/kandinsky-5/camera_lora/latents_video/hunyuan_512ext/
      text_probs:
        qwen25vl-32b-caption_detailed_medium: 1
      num_s3_loading_workers: 1
      tensor_ram_buffer_size: 128
      resolutions_probs: null
metrics:
  visual_size: ${common.visual_size}
  fps: ${common.fps}
  generate_params:
    scale_factor: ${common.scale_factor}
    scheduler_scale: 5
    num_steps: 50
    guidance_weight: 5.0
  dataloader:
    video_batch_size: 1
    image_batch_size: 1
    num_workers: 0
  root_dir: ${common.experiment_dir}/metrics
  null_text_emb:
    image: ${metrics.root_dir}/image/null_text_emb.pt
    video: ${metrics.root_dir}/video/null_text_emb.pt
  sbs_approx_video:
    max_samples: 8
    validation_interval: 250
    num_frames: 96
    data_dir: ${metrics.root_dir}/video/sbs_approx/data
    internvideo2_path: ${metrics.root_dir}/video/sbs_approx/models/internvideo2/internvideo2_stage2_config.py
    video_motion_path: ${metrics.root_dir}/video/sbs_approx/models/video_motion
    q_align_path: ${metrics.root_dir}/video/sbs_approx/models/q_align_video
    datasets:
      moviegen_bench_expanded:
        en:
          data_path: ${....data_dir}/moviegen_bench_expanded_encoded_captions
          data_file: ${....data_dir}/moviegen_bench_expanded_captions.json
          save_folder: ${common.log_dir}/${common.experiment_name}/sbs_approx_video_moviegen_bench_expanded
vae:
  checkpoint_path: /home/jovyan/vladimir/kandinsky5/pretrained_encoders/hunyuan_vae/
  name: hunyuan
text_embedder:
  qwen:
    mode: ''
    emb_size: 3584
    max_length: 256
    processor_checkpoint_path: /home/jovyan/vladimir/kandinsky5/pretrained_encoders/qwen2_5_vl_7b_instruct/
    model_checkpoint_path: /home/jovyan/shares/SR008.fs2/maria/saved_models/new_qwen.pt
    output_attentions: false
    attention_dropout: 0
    bos_token_id: 151643
    eos_token_id: 151645
    hidden_act: silu
    hidden_size: 3584
    image_token_id: 151655
    initializer_range: 0.02
    intermediate_size: 18944
    max_position_embeddings: 128000
    max_window_layers: 28
    num_attention_heads: 28
    num_hidden_layers: 28
    num_key_value_heads: 4
    rms_norm_eps: 1.0e-06
    rope_scaling:
      mrope_section:
      - 16
      - 24
      - 24
      rope_type: default
      type: default
    rope_theta: 1000000
    sliding_window: 32768
    text_config:
      attention_dropout: 0
      bos_token_id: 151643
      eos_token_id: 151645
      pad_token_id: 151643
      _attn_implementation: flash_attention_2
      hidden_act: silu
      hidden_size: 3584
      image_token_id: null
      initializer_range: 0.02
      intermediate_size: 18944
      layer_types:
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      - full_attention
      max_position_embeddings: 128000
      max_window_layers: 28
      model_type: qwen2_5_vl_text
      num_attention_heads: 28
      num_hidden_layers: 28
      num_key_value_heads: 4
      rms_norm_eps: 1.0e-06
      rope_scaling:
        mrope_section:
        - 16
        - 24
        - 24
        rope_type: default
        type: default
      rope_theta: 1000000
      sliding_window: null
      torch_dtype: bfloat16
      use_cache: true
      use_sliding_window: false
      video_token_id: null
      vision_end_token_id: 151653
      vision_start_token_id: 151652
      vision_token_id: 151654
      vocab_size: 152064
    tie_word_embeddings: false
    torch_dtype: bfloat16
    use_cache: true
    use_sliding_window: false
    video_token_id: 151656
    vision_config:
      _attn_implementation: flash_attention_2
      depth: 32
      fullatt_block_indexes:
      - 7
      - 15
      - 23
      - 31
      hidden_act: silu
      hidden_size: 1280
      in_channels: 3
      in_chans: 3
      initializer_range: 0.02
      intermediate_size: 3420
      model_type: qwen2_5_vl
      num_heads: 16
      out_hidden_size: 3584
      patch_size: 14
      spatial_merge_size: 2
      spatial_patch_size: 14
      temporal_patch_size: 2
      tokens_per_second: 2
      torch_dtype: bfloat16
      window_size: 112
    vision_end_token_id: 151653
    vision_start_token_id: 151652
    vision_token_id: 151654
    vocab_size: 152064
  clip:
    checkpoint_path: /home/jovyan/vladimir/kandinsky5/pretrained_encoders/clip_text/
    emb_size: 768
    max_length: 77
dit:
  checkpoint_path: /home/jovyan/shares/SR008.fs2/dmitrienko/kandinsky-5-0/saved_models/2B_r512ext_flash_8gpu_soft_rules/ema_model_10K/ema_shard_2gpu
  params:
    in_visual_dim: 16
    out_visual_dim: 16
    in_text_dim: 3584
    in_text_dim2: 768
    time_dim: 512
    patch_size:
    - 1
    - 2
    - 2
    model_dim: 1792
    ff_dim: 7168
    num_text_blocks: 2
    num_visual_blocks: 32
    axes_dims:
    - 16
    - 24
    - 24
    visual_cond: true
    attention_params:
      type: flash
      chunk: false
      causal: false
      local: false
      glob: false
      window: 3
lora:
  r: 64
  target_modules:
  - self_attention.to_query
  - self_attention.to_key
  - self_attention.to_value
  - self_attention.out_layer
  - cross_attention.to_query
  - cross_attention.to_key
  - cross_attention.to_value
  - cross_attention.out_layer
  - feed_forward.in_layer
  - feed_forward.out_layer
model_size: 2.1B
